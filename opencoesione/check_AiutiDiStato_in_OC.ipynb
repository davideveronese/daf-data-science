{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Work in progress - openCoesione with Comune as key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Runs with \"daf\" enviroment in repo\n",
    "\n",
    "%config Completer.use_jedi = False #fix TAB slowness with big frames\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import gc #garbage collector\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)\n",
    "\n",
    "def load_and_stack_data(prefix):\n",
    "    fileList = glob.glob('./../pac_opencoesione/%s*.csv' % prefix)\n",
    "    \n",
    "    if prefix == 'progetti':\n",
    "        dtypesDict = pd.read_csv(\n",
    "            './openCoesione_dtypes.csv', index_col='Variabile', squeeze=True).to_dict()\n",
    "        dateCols = [name for name in dtypesDict.keys() if dtypesDict[name] == 'datetime64']\n",
    "        for name in dateCols: del dtypesDict[name]\n",
    "        frames = list(map(lambda f: pd.read_csv(\n",
    "            f, sep=';', dtype=dtypesDict, index_col=0, na_values=[' ', '  ']), fileList))\n",
    "        data = pd.concat(frames, axis=0)\n",
    "        data[dateCols] = data[dateCols].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "        \n",
    "        # drop duplicates including index when checking\n",
    "        indexColName = data.index.name\n",
    "        data.reset_index(inplace=True)\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        data.set_index(indexColName, inplace=True)\n",
    "        \n",
    "        # clean remaining duplicate indexes by picking the row that has fewer N/A\n",
    "        bDuplicate = data.index.duplicated(keep=False)\n",
    "        if any(bDuplicate):\n",
    "            print('%i duplicate indexes found' % sum(bDuplicate))\n",
    "            duplRows = data[bDuplicate].copy()\n",
    "            duplRows['NumberNA'] = duplRows.isna().sum(axis=1)\n",
    "            duplRows.sort_values('NumberNA', inplace=True)\n",
    "            # recomibine into final frame\n",
    "            data = pd.concat([data[~bDuplicate], duplRows[duplRows.index.duplicated(keep='first')]])\n",
    "        \n",
    "    else:\n",
    "        # infer types for other datasets (temporary)\n",
    "        frames = list(map(lambda f: pd.read_csv(f, sep=';', index_col=False), fileList))\n",
    "        data = pd.concat(frames, axis=0)\n",
    "        \n",
    "        # drop duplicates excluding index\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        \n",
    "    print('Imported %s' % prefix)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/anaconda3/envs/daf/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning: Columns (4,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported soggetti\n"
     ]
    }
   ],
   "source": [
    "# load soggetti\n",
    "listaMise =  pd.read_csv('./../MISE Aiuti/data/D_general/ListIvaCodFisc.csv', sep=';', index_col=False)\n",
    "soggetti = load_and_stack_data('soggetti')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13651\n"
     ]
    }
   ],
   "source": [
    "print(len(listaMise.values[listaMise.isin(soggetti.OC_CODICE_FISCALE_SOGG.values)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join: pagamenti + (progetti + soggetti==2) e luoghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: JOIN soggetti-progetti // soggetti might have more than 1 acting entity, \n",
    "# initally drop them  %TODO: allow other progr soggetti and split payements\n",
    "\n",
    "soggettiAttuatori = soggetti[\n",
    "    (soggetti.SOGG_PROGR_RUOLO == 1) & (soggetti.SOGG_COD_RUOLO == 2)].set_index('COD_LOCALE_PROGETTO')  \n",
    "assert not any(soggettiAttuatori.index.duplicated()), 'Attuatori duplicati'\n",
    "\n",
    "newUnion = progetti[progetti.OC_FLAG_REGIONE_UNICA=='1'].join(soggettiAttuatori)\n",
    "print('---CONSIDERATI PROGETTI con solo una regione')\n",
    "firstJoinTotPagamenti = newUnion.TOT_PAGAMENTI.sum()\n",
    "\n",
    "del progetti\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: JOIN progetti-luoghi // luoghi might have more than one row per project,\n",
    "# initally drop them  %TODO: allow other luoghi, check match with soggetti and split payements\n",
    "\n",
    "luoghiMatch = luoghi[luoghi.OC_FLAG_CAP_PROG==1].set_index('COD_LOCALE_PROGETTO')\n",
    "\n",
    "luoghiMatch = luoghiMatch[~luoghiMatch.index.duplicated(keep='first')] #TODO: analyse repeated luoghi \n",
    "#assert not any(luoghiMatch.index.duplicated()), 'Luoghi duplicati'\n",
    "\n",
    "newUnion = newUnion.join(luoghiMatch)\n",
    "assert newUnion.TOT_PAGAMENTI.sum() == firstJoinTotPagamenti, 'Inconsistent join'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: JOIN pagamenti-progetti // fill pagamenti data with the above info\n",
    "\n",
    "# check pagamenti sums\n",
    "pagamenti = load_and_stack_data('pagamenti')\n",
    "origSum = pagamenti['TOT_PAGAMENTI'].sum() # ok, around 60B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newUnion.join(pagamenti.set_index('COD_LOCALE_PROGETTO'),  lsuffix='all_')['TOT_PAGAMENTI'].sum()\n",
    "newUnion = newUnion.join(pagamenti.set_index('COD_LOCALE_PROGETTO'),  lsuffix='_summary')\n",
    "\n",
    "del pagamenti\n",
    "gc.collect()\n",
    "#print(pagamenti['TOT_PAGAMENTI'].sum())\n",
    "#print(newUnion['TOT_PAGAMENTI'].sum())\n",
    "\n",
    "\n",
    "#newUnion.head().join(pagamenti.set_index('COD_LOCALE_PROGETTO'),  lsuffix='all_').columns #['TOT_PAGAMENTI_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiSoggetto = soggetti[(soggetti.SOGG_PROGR_RUOLO > 1) & (soggetti.SOGG_COD_RUOLO == 2)] \n",
    "\n",
    "bProgettoMultiSogg = \n",
    "\n",
    "print(len(multiSoggettoKeys))\n",
    "\n",
    "\n",
    "#print(soggetti.COD_DIMENSIONE_SOGG.unique())\n",
    "#print(soggetti.groupby(['COD_DIMENSIONE_SOGG', 'DESCR_FORMA_GIURIDICA_SOGG']).count())\n",
    "#print(soggetti[soggetti.COD_DIMENSIONE_SOGG.isnull()].groupby('DESCR_FORMA_GIURIDICA_SOGG')['OC_CODICE_FISCALE_SOGG'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary on beneficiary types\n",
    "soggetti.groupby('DESCR_FORMA_GIURIDICA_SOGG')['OC_CODICE_FISCALE_SOGG'].nunique().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
